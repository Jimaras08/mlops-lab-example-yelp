{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.autograd as autograd\n",
    "import pickle\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharVectorizer():\n",
    "    def __init__(self, maxlen=10, alphabet=\"\"\"abcdefghijklmnopqrstuvwxyz0123456789-,;.!?:'\\\"/\\\\|_@#$%^&*~`+-=<>()[]\\{\\}\"\"\"):\n",
    "        \n",
    "        self.alphabet = alphabet\n",
    "        self.maxlen = maxlen\n",
    "        self.char_dict = {k: i for i, k in enumerate(self.alphabet, 1)} # indice zero is reserved to blank and unknown characters\n",
    "\n",
    "    def transform(self,sentences):\n",
    "        \"\"\"\n",
    "        sentences: list of string\n",
    "        list of review, review is a list of sequences, sequences is a list of int\n",
    "        \"\"\"\n",
    "        sequences = []\n",
    "        for sentence in sentences:\n",
    "            seq = [self.char_dict.get(char, 0) for char in sentence[:self.maxlen].lower()]\n",
    "            sequences.append(seq)                \n",
    "        return sequences\n",
    "    \n",
    "    def get_params(self):\n",
    "        params = vars(self)\n",
    "        return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphabet=\"\"\"abcdefghijklmnopqrstuvwxyz0123456789-,;.!?:'\\\"/\\\\|_@#$%^&*~`+-=<>()[]\\{\\}\"\"\"\n",
    "\n",
    "int2char = dict(enumerate(alphabet))\n",
    "char2int = {ch: ii for ii, ch in int2char.items()}\n",
    "\n",
    "text = 'hellotest'\n",
    "# encode the text\n",
    "encoded = np.array([char2int[ch] for ch in text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(arr, n_labels):\n",
    "    \n",
    "    # Initialize the the encoded array\n",
    "    one_hot = np.zeros((np.multiply(*arr.shape), n_labels), dtype=np.float32)\n",
    "    \n",
    "    # Fill the appropriate elements with ones\n",
    "    one_hot[np.arange(one_hot.shape[0]), arr.flatten()] = 1.\n",
    "    \n",
    "    # Finally reshape it to get back to the original array\n",
    "    one_hot = one_hot.reshape((*arr.shape, n_labels))\n",
    "    \n",
    "    return one_hot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7,  4, 11, 11, 14, 19,  4, 18, 19])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.zeros(len(alphabet), self.l0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'dasdad'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-cc5e8cd10b1b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# encode the text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mencoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mchar2int\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mch\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'dasdad'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-16-cc5e8cd10b1b>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# encode the text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mencoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mchar2int\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mch\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'dasdad'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: 'dasdad'"
     ]
    }
   ],
   "source": [
    "# encode the text\n",
    "encoded = np.array([char2int[ch] for ch in text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, n_classes=2, input_length=1014, input_dim=68,\n",
    "                 n_conv_filters=256,\n",
    "                 n_fc_neurons=1024):\n",
    "        super(CNN, self).__init__()\n",
    "\n",
    "        self.layer1 = nn.Sequential(nn.Conv1d(input_dim, n_conv_filters, kernel_size=7, padding=0), nn.ReLU(), nn.MaxPool1d(3))\n",
    "        self.layer2 = nn.Sequential(nn.Conv1d(n_conv_filters, n_conv_filters, kernel_size=7, padding=0), nn.ReLU(), nn.MaxPool1d(3))\n",
    "        self.layer3 = nn.Sequential(nn.Conv1d(n_conv_filters, n_conv_filters, kernel_size=3, padding=0), nn.ReLU())\n",
    "        self.layer4 = nn.Sequential(nn.Conv1d(n_conv_filters, n_conv_filters, kernel_size=3, padding=0), nn.ReLU())\n",
    "        self.layer5 = nn.Sequential(nn.Conv1d(n_conv_filters, n_conv_filters, kernel_size=3, padding=0), nn.ReLU())\n",
    "        self.layer6 = nn.Sequential(nn.Conv1d(n_conv_filters, n_conv_filters, kernel_size=3, padding=0), nn.ReLU(), nn.MaxPool1d(3))\n",
    "\n",
    "        # layer 6 output length = (input_length - 96) / 27\n",
    "        last_cnn_layer_len = (input_length - 96) / 27\n",
    "        dim = int(last_cnn_layer_len * n_conv_filters)\n",
    "        self.layer7 = nn.Sequential(nn.Linear(dim, n_fc_neurons), nn.Dropout(0.5))\n",
    "        self.layer8 = nn.Sequential(nn.Linear(n_fc_neurons, n_fc_neurons), nn.Dropout(0.5))\n",
    "        self.layer9 = nn.Linear(n_fc_neurons, n_classes)\n",
    "\n",
    "        if n_conv_filters == 256 and n_fc_neurons == 1024:\n",
    "            self.__init_weights(mean=0.0, std=0.05)\n",
    "        elif n_conv_filters == 1024 and n_fc_neurons == 2048:\n",
    "            self.__init_weights(mean=0.0, std=0.02)\n",
    "\n",
    "    def __init_weights(self, mean=0.0, std=0.05):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv1d):\n",
    "                m.weight.data.normal_(mean, std)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                m.weight.data.normal_(mean, std)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = x.transpose(1, 2)\n",
    "\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = self.layer5(out)\n",
    "        out = self.layer6(out)\n",
    "\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.layer7(out)\n",
    "        out = self.layer8(out)\n",
    "        out = self.layer9(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class YelpReviews(Dataset):\n",
    "    def __init__(self, dataset_path, key, l0 = 1014):\n",
    "        self.dataset_path = dataset_path\n",
    "        self.key = key # Train, test, val\n",
    "\n",
    "        # read alphabet\n",
    "        self.loadAlphabet(alphabet_path)\n",
    "        self.load(label_data_path)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        X = self.oneHotEncode(idx)\n",
    "        y = self.y[idx]\n",
    "        return X, y\n",
    "\n",
    "    def load(self, dataset_path, key):\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
