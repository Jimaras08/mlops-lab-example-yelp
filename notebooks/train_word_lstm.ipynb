{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchtext import data\n",
    "import torch.nn as nn\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install torch==1.6 torchtext==0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paulo/.local/lib/python3.6/site-packages/torchtext/data/field.py:150: UserWarning: Field class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
      "  warnings.warn('{} class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.'.format(self.__class__.__name__), UserWarning)\n",
      "/home/paulo/.local/lib/python3.6/site-packages/torchtext/data/field.py:150: UserWarning: LabelField class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
      "  warnings.warn('{} class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "# Create reproducible results\n",
    "\n",
    "SEED = 42\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Create text and label fields\n",
    "TEXT = data.Field(tokenize = 'spacy', include_lengths = True)\n",
    "LABEL = data.LabelField(dtype = torch.float)\n",
    "\n",
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dataset = pd.read_pickle('notebooks/dataset_split.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "      <th>cool</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UmFMZ8PyXZTY2QcwzsfQYA</td>\n",
       "      <td>nIJD_7ZXHq-FX8byPMOkMQ</td>\n",
       "      <td>lbrU8StCq3yDfr-QMnGrmQ</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>I am actually horrified this place is still in...</td>\n",
       "      <td>2013-12-07 03:16:52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LG2ZaYiOgpr2DK_90pYjNw</td>\n",
       "      <td>V34qejxNsCbcgD8C0HVk-Q</td>\n",
       "      <td>HQl28KMwrEKHqhFrrDqVNQ</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>I love Deagan's. I do. I really do. The atmosp...</td>\n",
       "      <td>2015-12-05 03:18:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6TdNDKywdbjoTkizeMce8A</td>\n",
       "      <td>UgMW8bLE0QMJDCkQ1Ax5Mg</td>\n",
       "      <td>IS4cv902ykd8wj1TR0N3-A</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Oh happy day, finally have a Canes near my cas...</td>\n",
       "      <td>2017-01-14 21:56:57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>L2O_INwlrRuoX05KSjc4eg</td>\n",
       "      <td>5vD2kmE25YBrbayKhykNxQ</td>\n",
       "      <td>nlxHRv1zXGT0c0K51q3jDg</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>This is definitely my favorite fast food sub s...</td>\n",
       "      <td>2013-05-07 07:25:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ZayJ1zWyWgY9S_TRLT_y9Q</td>\n",
       "      <td>aq_ZxGHiri48TUXJlpRkCQ</td>\n",
       "      <td>Pthe4qk5xh4n-ef-9bvMSg</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Really good place with simple decor, amazing f...</td>\n",
       "      <td>2015-11-05 23:11:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8021116</th>\n",
       "      <td>43ugcDASS-mGv0eYozge_g</td>\n",
       "      <td>kyxGYZpa4UNmA7Q0gmQmYA</td>\n",
       "      <td>H85um1dDQHAeUJ6AqYIqww</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>I'm still reminded of my move every time I see...</td>\n",
       "      <td>2019-12-10 12:07:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8021117</th>\n",
       "      <td>LAzw2u1ucY722ryLEXHdgg</td>\n",
       "      <td>6DMFD3BRp-MVzDQelRx5UQ</td>\n",
       "      <td>XW2kaXdahICaJ27A0dhGHg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Fricken unbelievable, I ordered 2 space heater...</td>\n",
       "      <td>2019-12-11 01:07:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8021118</th>\n",
       "      <td>gMDU14Fa_DVIcPvsKtubJA</td>\n",
       "      <td>_g6P8H3-qfbz1FxbffS68g</td>\n",
       "      <td>IsoLzudHC50oJLiEWpwV-w</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Solid American food with a southern comfort fl...</td>\n",
       "      <td>2019-12-10 04:15:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8021119</th>\n",
       "      <td>EcY_p50zPIQ2R6rf6-5CjA</td>\n",
       "      <td>Scmyz7MK4TbXXYcaLZxIxQ</td>\n",
       "      <td>kDCyqlYcstqnoqnfBRS5Og</td>\n",
       "      <td>5.0</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>I'm honestly not sure how I have never been to...</td>\n",
       "      <td>2019-06-06 15:01:53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8021121</th>\n",
       "      <td>nK0JGgr8aO4mcFPU4pDOEA</td>\n",
       "      <td>fiA6ztHPONUkmX6yKIXyHg</td>\n",
       "      <td>2SbyRgHWuWNlq18eHAx95Q</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Oh yeah! Not only that the service was good, t...</td>\n",
       "      <td>2019-12-07 00:29:55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5630014 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      review_id                 user_id  \\\n",
       "1        UmFMZ8PyXZTY2QcwzsfQYA  nIJD_7ZXHq-FX8byPMOkMQ   \n",
       "2        LG2ZaYiOgpr2DK_90pYjNw  V34qejxNsCbcgD8C0HVk-Q   \n",
       "4        6TdNDKywdbjoTkizeMce8A  UgMW8bLE0QMJDCkQ1Ax5Mg   \n",
       "5        L2O_INwlrRuoX05KSjc4eg  5vD2kmE25YBrbayKhykNxQ   \n",
       "6        ZayJ1zWyWgY9S_TRLT_y9Q  aq_ZxGHiri48TUXJlpRkCQ   \n",
       "...                         ...                     ...   \n",
       "8021116  43ugcDASS-mGv0eYozge_g  kyxGYZpa4UNmA7Q0gmQmYA   \n",
       "8021117  LAzw2u1ucY722ryLEXHdgg  6DMFD3BRp-MVzDQelRx5UQ   \n",
       "8021118  gMDU14Fa_DVIcPvsKtubJA  _g6P8H3-qfbz1FxbffS68g   \n",
       "8021119  EcY_p50zPIQ2R6rf6-5CjA  Scmyz7MK4TbXXYcaLZxIxQ   \n",
       "8021121  nK0JGgr8aO4mcFPU4pDOEA  fiA6ztHPONUkmX6yKIXyHg   \n",
       "\n",
       "                    business_id  stars  useful  funny  cool  \\\n",
       "1        lbrU8StCq3yDfr-QMnGrmQ    1.0       1      1     0   \n",
       "2        HQl28KMwrEKHqhFrrDqVNQ    5.0       1      0     0   \n",
       "4        IS4cv902ykd8wj1TR0N3-A    4.0       0      0     0   \n",
       "5        nlxHRv1zXGT0c0K51q3jDg    5.0       2      0     0   \n",
       "6        Pthe4qk5xh4n-ef-9bvMSg    5.0       1      0     0   \n",
       "...                         ...    ...     ...    ...   ...   \n",
       "8021116  H85um1dDQHAeUJ6AqYIqww    1.0       0      0     0   \n",
       "8021117  XW2kaXdahICaJ27A0dhGHg    1.0       1      0     1   \n",
       "8021118  IsoLzudHC50oJLiEWpwV-w    3.0       1      3     1   \n",
       "8021119  kDCyqlYcstqnoqnfBRS5Og    5.0      15      6    13   \n",
       "8021121  2SbyRgHWuWNlq18eHAx95Q    5.0       2      0     2   \n",
       "\n",
       "                                                      text  \\\n",
       "1        I am actually horrified this place is still in...   \n",
       "2        I love Deagan's. I do. I really do. The atmosp...   \n",
       "4        Oh happy day, finally have a Canes near my cas...   \n",
       "5        This is definitely my favorite fast food sub s...   \n",
       "6        Really good place with simple decor, amazing f...   \n",
       "...                                                    ...   \n",
       "8021116  I'm still reminded of my move every time I see...   \n",
       "8021117  Fricken unbelievable, I ordered 2 space heater...   \n",
       "8021118  Solid American food with a southern comfort fl...   \n",
       "8021119  I'm honestly not sure how I have never been to...   \n",
       "8021121  Oh yeah! Not only that the service was good, t...   \n",
       "\n",
       "                        date  \n",
       "1        2013-12-07 03:16:52  \n",
       "2        2015-12-05 03:18:11  \n",
       "4        2017-01-14 21:56:57  \n",
       "5        2013-05-07 07:25:25  \n",
       "6        2015-11-05 23:11:05  \n",
       "...                      ...  \n",
       "8021116  2019-12-10 12:07:55  \n",
       "8021117  2019-12-11 01:07:06  \n",
       "8021118  2019-12-10 04:15:00  \n",
       "8021119  2019-06-06 15:01:53  \n",
       "8021121  2019-12-07 00:29:55  \n",
       "\n",
       "[5630014 rows x 9 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['X_train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = dataset['X_train'].loc[:, ['text', 'stars']][0:100000]\n",
    "train_df['stars'] = (train_df['stars'] >= 3.0).astype(int)\n",
    "train_df.columns = ['text', 'target']\n",
    "\n",
    "val_df = dataset['X_val'].loc[:, ['text', 'stars']][0:50000]\n",
    "val_df['stars'] = (val_df['stars'] >= 3.0).astype(int)\n",
    "val_df.columns = ['text', 'target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I am actually horrified this place is still in...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I love Deagan's. I do. I really do. The atmosp...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Oh happy day, finally have a Canes near my cas...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>This is definitely my favorite fast food sub s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Really good place with simple decor, amazing f...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target\n",
       "1  I am actually horrified this place is still in...       0\n",
       "2  I love Deagan's. I do. I really do. The atmosp...       1\n",
       "4  Oh happy day, finally have a Canes near my cas...       1\n",
       "5  This is definitely my favorite fast food sub s...       1\n",
       "6  Really good place with simple decor, amazing f...       1"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/paulo'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.chdir('..')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.utils import DataFrameDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paulo/.local/lib/python3.6/site-packages/torchtext/data/example.py:78: UserWarning: Example class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
      "  warnings.warn('Example class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.', UserWarning)\n"
     ]
    }
   ],
   "source": [
    "fields = [('text', TEXT), ('label', LABEL)]\n",
    "\n",
    "train_ds, val_ds = DataFrameDataset.splits(fields, train_df=train_df, val_df=val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': ['This', 'was', 'our', 'choice', ',', 'by', 'default', ',', 'for', 'New', 'Year', \"'s\", 'Eve', 'dinner', 'this', 'year', '.', 'See', ',', 'we', 'chose', 'not', 'to', 'make', 'reservations', ',', 'but', 'instead', 'just', 'wing', 'it', 'and', 'see', 'where', 'we', 'could', 'get', 'in', '.', 'They', 'had', 'some', 'early', 'dining', 'availability', ',', 'so', 'we', 'jumped', 'on', 'it', '.', 'Their', 'special', 'New', 'Year', \"'s\", '\"', 'Paint', 'the', 'Town', 'Gold', '\"', 'menu', 'did', 'not', 'disappoint', '.', '\\n\\n', 'Located', 'in', 'the', 'beautiful', 'Mandalay', 'Bay', 'restaurant', 'row', ',', 'Kumi', 'is', 'a', 'gorgeous', 'display', 'of', 'style', 'and', 'food', 'artistry', '.', 'Every', 'course', 'was', 'surprisingly', 'delicious', ',', 'and', 'plated', 'interestingly', '.', '\\n\\n', 'Service', 'was', 'very', 'good', ',', 'seriously', 'on', 'point', '.', 'Right', 'up', 'until', 'the', 'dessert', 'course', '...', 'after', '30', 'minutes', 'of', 'waiting', 'for', 'it', ',', 'we', 'finally', 'requested', 'the', 'check', 'as', 'we', 'had', 'an', 'event', 'to', 'get', 'to', '.', 'One', 'of', 'our', 'attendants', 'felt', 'bad', 'and', 'offered', 'to', 'quickly', 'grab', 'it', 'for', 'us', 'but', 'we', 'were', 'in', 'danger', 'of', 'being', 'late', 'so', 'we', 'opted', 'not', 'to', 'take', 'him', 'up', 'on', 'it', '.', '\\n\\n', 'It', \"'s\", 'a', 'beautiful', ',', 'albeit', 'very', 'pricey', 'experience', 'for', 'dinner', '.', 'We', 'would', 'return', 'for', 'special', 'occasions', 'only', '.'], 'label': 1}\n"
     ]
    }
   ],
   "source": [
    "# Random example\n",
    "print(vars(train_ds[15]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random example\n",
    "# print(vars(test_ds[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build vocabulary\n",
    "# MAX_VOCAB_SIZE = 25000\n",
    "MAX_VOCAB_SIZE = 10000\n",
    "\n",
    "TEXT.build_vocab(train_ds, \n",
    "                 max_size = MAX_VOCAB_SIZE, \n",
    "                 vectors = 'glove.6B.200d',\n",
    "                 unk_init = torch.Tensor.zero_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL.build_vocab(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paulo/.local/lib/python3.6/site-packages/torchtext/data/iterator.py:48: UserWarning: BucketIterator class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
      "  warnings.warn('{} class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "# Build iterators\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "device = torch.device('cuda:2' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "train_iterator, valid_iterator = data.BucketIterator.splits(\n",
    "    (train_ds, val_ds), \n",
    "    batch_size = BATCH_SIZE,\n",
    "    sort_within_batch = True,\n",
    "    device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# train_it = DataLoader(train_ds, batch_size = BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=2)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare hyperparameters\n",
    "num_epochs = 25\n",
    "learning_rate = 0.001\n",
    "\n",
    "INPUT_DIM = len(TEXT.vocab)\n",
    "EMBEDDING_DIM = 200\n",
    "HIDDEN_DIM = 128\n",
    "OUTPUT_DIM = 1\n",
    "N_LAYERS = 2\n",
    "BIDIRECTIONAL = True\n",
    "DROPOUT = 0.2\n",
    "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token] # padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10002"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "INPUT_DIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.lstm import LSTM_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating instance of our LSTM_net class\n",
    "\n",
    "model = LSTM_net(INPUT_DIM,\n",
    "            EMBEDDING_DIM, \n",
    "            HIDDEN_DIM, \n",
    "            OUTPUT_DIM,\n",
    "            N_LAYERS, \n",
    "            BIDIRECTIONAL, \n",
    "            DROPOUT,\n",
    "            PAD_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10002, 200])\n"
     ]
    }
   ],
   "source": [
    "pretrained_embeddings = TEXT.vocab.vectors\n",
    "\n",
    "print(pretrained_embeddings.shape)\n",
    "model.embedding.weight.data.copy_(pretrained_embeddings)\n",
    "model.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.to(device) #CNN to GPU\n",
    "\n",
    "# Loss and optimizer\n",
    "# criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow.pytorch\n",
    "from mlflow.tracking import MlflowClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "INFO:lightning:GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "INFO:lightning:TPU available: False, using: 0 TPU cores\n",
      "CUDA_VISIBLE_DEVICES: [0]\n",
      "INFO:lightning:CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    }
   ],
   "source": [
    "import pytorch_lightning as pl\n",
    "trainer = pl.Trainer(gpus=[2], max_epochs=20, progress_bar_refresh_rate=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021/01/25 17:39:48 INFO mlflow.utils.autologging_utils: pytorch autologging will track hyperparameters, performance metrics, model artifacts, and lineage information for the current pytorch workflow to the MLflow run with ID '581efad2ea244cdf9e78c5cbbff5e750'\n",
      "\n",
      "  | Name      | Type      | Params\n",
      "----------------------------------------\n",
      "0 | embedding | Embedding | 2 M   \n",
      "1 | rnn       | LSTM      | 733 K \n",
      "2 | fc1       | Linear    | 257   \n",
      "3 | act       | Sigmoid   | 0     \n",
      "INFO:lightning:\n",
      "  | Name      | Type      | Params\n",
      "----------------------------------------\n",
      "0 | embedding | Embedding | 2 M   \n",
      "1 | rnn       | LSTM      | 733 K \n",
      "2 | fc1       | Linear    | 257   \n",
      "3 | act       | Sigmoid   | 0     \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c9a0191b71144dd8f5ec4c97ee7b613",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validation sanity check', layout=Layoutâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d449e04c286454e84b5786b2cbb26d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), maxâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bea0a7711e93401994a9810d218bb4c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), mâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving latest checkpoint..\n",
      "INFO:lightning:Saving latest checkpoint..\n",
      "2021/01/25 17:41:18 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during autologging: Cloudpickle Error: Unknown type <class 'src.data.utils.DataFrameDataset'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Auto log all MLflow entities\n",
    "mlflow.pytorch.autolog()\n",
    "\n",
    "# Train the model\n",
    "with mlflow.start_run() as run:\n",
    "    trainer.fit(model, train_iterator, valid_iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTM_net(\n",
       "  (embedding): Embedding(10002, 200, padding_idx=1)\n",
       "  (rnn): LSTM(200, 128, num_layers=2, batch_first=True, dropout=0.2, bidirectional=True)\n",
       "  (fc1): Linear(in_features=256, out_features=1, bias=True)\n",
       "  (act): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_id: 9169cc31c5fc4420b310323be7a164f9\n",
      "artifacts: []\n",
      "params: {'optimizer_name': 'Adam', 'lr': '0.02', 'betas': '(0.9, 0.999)', 'amsgrad': 'False', 'eps': '1e-08', 'weight_decay': '0', 'epochs': '20'}\n",
      "metrics: {'val_loss': 0.507030189037323}\n",
      "tags: {'Mode': 'training'}\n"
     ]
    }
   ],
   "source": [
    "def print_auto_logged_info(r):\n",
    "\n",
    "    tags = {k: v for k, v in r.data.tags.items() if not k.startswith(\"mlflow.\")}\n",
    "    artifacts = [f.path for f in MlflowClient().list_artifacts(r.info.run_id, \"model\")]\n",
    "    print(\"run_id: {}\".format(r.info.run_id))\n",
    "    print(\"artifacts: {}\".format(artifacts))\n",
    "    print(\"params: {}\".format(r.data.params))\n",
    "    print(\"metrics: {}\".format(r.data.metrics))\n",
    "    print(\"tags: {}\".format(tags))\n",
    "    \n",
    "# fetch the auto logged parameters and metrics\n",
    "print_auto_logged_info(mlflow.get_run(run_id=run.info.run_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "t = time.time()\n",
    "loss=[]\n",
    "acc=[]\n",
    "val_acc=[]\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    train_loss, train_acc = train(model, train_iterator)\n",
    "    valid_loss, valid_acc = evaluate(model, valid_iterator)\n",
    "    \n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "    print(f'\\t Val. Acc: {valid_acc*100:.2f}%')\n",
    "    \n",
    "    #save the best model\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'saved_weights.pt')\n",
    "    \n",
    "    loss.append(train_loss)\n",
    "    acc.append(train_acc)\n",
    "    val_acc.append(valid_acc)\n",
    "    \n",
    "print(f'time:{time.time()-t:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill \n",
    "\n",
    "with open(\"TEXT.Field\", \"wb\") as f:\n",
    "     dill.dump(TEXT, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inference \n",
    "import spacy\n",
    "nlp = spacy.load('en')          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTM_net(\n",
       "  (embedding): Embedding(10002, 200, padding_idx=1)\n",
       "  (rnn): LSTM(200, 128, num_layers=2, batch_first=True, dropout=0.2, bidirectional=True)\n",
       "  (fc1): Linear(in_features=256, out_features=1, bias=True)\n",
       "  (act): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "def predict(model, sentence):\n",
    "    print(device)\n",
    "    tokenized = [tok.text for tok in nlp.tokenizer(sentence)]  #tokenize the sentence \n",
    "    indexed = [TEXT.vocab.stoi[t] for t in tokenized]          #convert to integer sequence\n",
    "    length = [len(indexed)]                                    #compute no. of words\n",
    "    tensor = torch.LongTensor(indexed).to(device)              #convert to tensor\n",
    "    tensor = tensor.unsqueeze(1).T                             #reshape in form of batch,no. of words\n",
    "    length_tensor = torch.LongTensor(length)                   #convert to tensor\n",
    "    \n",
    "    print(tensor.shape)\n",
    "    print(length_tensor)\n",
    "    prediction = model(tensor, length_tensor)                  #prediction\n",
    "    print(prediction.shape)\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.rnn.batch_first=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTM_net(\n",
       "  (embedding): Embedding(10002, 200, padding_idx=1)\n",
       "  (rnn): LSTM(200, 128, num_layers=2, batch_first=True, dropout=0.2, bidirectional=True)\n",
       "  (fc1): Linear(in_features=256, out_features=1, bias=True)\n",
       "  (act): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "torch.Size([1, 5])\n",
      "tensor([5])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected `len(lengths)` to be equal to batch_size, but got 1 (batch_size=5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-179-973c19eb3d98>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"terrible horrible restaurant abcd efg\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-173-6c4d8b02f822>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(model, sentence)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlength_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlength_tensor\u001b[0m\u001b[0;34m)\u001b[0m                  \u001b[0;31m#prediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Yelp_Dataset/models/lstm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, text, text_lengths)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;31m# Pack padded sequences sequence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0mpacked_embedded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_padded_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_lengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;31m# hidden = (num layers * num directions, batch size, hid dim)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/utils/rnn.py\u001b[0m in \u001b[0;36mpack_padded_sequence\u001b[0;34m(input, lengths, batch_first, enforce_sorted)\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m     \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m         \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pack_padded_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_first\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_packed_sequence_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected `len(lengths)` to be equal to batch_size, but got 1 (batch_size=5)"
     ]
    }
   ],
   "source": [
    "predict(model, \"terrible horrible restaurant abcd efg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
